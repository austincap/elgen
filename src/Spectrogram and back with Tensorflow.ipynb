{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from scipy.io.wavfile import read\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GM - 1-01 Prelude.wav', 'makushin.mp3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.\\input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, audioData = read('.\\input\\GM - 1-01 Prelude.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate: 16000\n",
      "Length: 2:41\n",
      "Data type: int16\n"
     ]
    }
   ],
   "source": [
    "print(\"Rate:\", rate)\n",
    "\n",
    "lengthMinutes = audioData.shape[0] / rate //  60\n",
    "lengthSeconds = (audioData.shape[0] / rate / 60 - lengthMinutes) * 60\n",
    "lengthStr = '{}:{}'.format(int(lengthMinutes), int(lengthSeconds))\n",
    "print(\"Length:\", lengthStr)\n",
    "print(\"Data type:\", audioData.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 14 29 ...  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(audioData)\n",
    "channel1 = audioData#[:,0] # left channel\n",
    "channel2 = audioData#[:,1] # right channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFT_LENGTH = 1024\n",
    "WINDOW_LENGTH = 512\n",
    "WINDOW_STEP = int(WINDOW_LENGTH / 2)\n",
    "magnitudeMin = float(\"inf\")\n",
    "magnitudeMax = float(\"-inf\")\n",
    "phaseMin = -math.pi\n",
    "phaseMax = math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    hello = tf.constant('Hello, Tensorflow!')\n",
    "    print(sess.run(hello))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher frequencies are less visible on spectrogram so we need to amplify it logarithmically.\n",
    "We also need a fucntion to reverse this process while extracting wav back from spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log10(x):\n",
    "  numerator = tf.log(x)\n",
    "  denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n",
    "  return numerator / denominator\n",
    "\n",
    "def amplifyMagnitudeByLog(d):\n",
    "    return 188.301 * math.log10(d + 1)\n",
    "\n",
    "def weakenAmplifiedMagnitude(d):\n",
    "    return math.pow(10, d/188.301)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate spectrogram for wave\n",
    "Get fragment of the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#take 10 seconds from 0:30 to 0:40\n",
    "signal_fragment = channel1[30*rate:35*rate]# channel1[:]#\n",
    "#plot the signal\n",
    "#plt.figure(1, figsize=(15, 5))\n",
    "#plt.subplot(121)\n",
    "#plt.plot(signal_fragment)\n",
    "#plt.title('10 seconds of audio data')\n",
    "#plt.subplot(122)\n",
    "#plt.plot(signal_fragment[:200])\n",
    "#plt.title('Small fragment of audio data')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSpectrogramForWave(signal):\n",
    "    print('test')\n",
    "    with tf.Session() as sess:\n",
    "        start_time = time.time()\n",
    "        signals = tf.placeholder(tf.float32, [None])\n",
    "        stft = tf.contrib.signal.stft(signals, \n",
    "                                    frame_length=WINDOW_LENGTH, \n",
    "                                    frame_step=WINDOW_STEP,\n",
    "                                    fft_length=FFT_LENGTH,\n",
    "                                    pad_end=True)\n",
    "        #log_offset = 1e-6\n",
    "        #mags = tf.transpose(tf.log(tf.abs(stft) + log_offset))\n",
    "        mags = tf.transpose(tf.abs(stft))\n",
    "        phases = tf.transpose(tf.angle(stft))\n",
    "        m_max = tf.math.reduce_max(mags)\n",
    "        m_min = tf.math.reduce_min(mags)\n",
    "        # convert to pix\n",
    "        mags = (mags - m_min) / (m_max - m_min) * 510\n",
    "        mags = log10(mags + 1) * 188.301\n",
    "        mags = tf.to_int32(mags)\n",
    "        mags = tf.reverse(mags,[0])\n",
    "        \n",
    "        phases = (phases + math.pi) / (2*math.pi) * 255\n",
    "        phases = tf.cast(phases, tf.uint8)\n",
    "        phases = tf.reverse(phases,[0])\n",
    "        \n",
    "        red = tf.cast(tf.clip_by_value(mags, 0, 255), tf.uint8)\n",
    "        green = tf.cast(tf.clip_by_value(mags - 255, 0, 255), tf.uint8)\n",
    "        rgb = tf.stack([red, green, phases], axis=2)\n",
    "        rgbArray, mags = sess.run([rgb, mags], feed_dict={signals: signal})\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('%.2f' % elapsed_time, 's', sep='')\n",
    "    img = Image.fromarray(rgbArray, 'RGB')\n",
    "    img.save(\".\\input\\spectrogram.png\",\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "generateSpectrogramForWave(signal_fragment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
